{"cells":[{"cell_type":"markdown","metadata":{"id":"l2xc1EQjq3LY"},"source":["## Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":749674,"status":"ok","timestamp":1670793361633,"user":{"displayName":"Kevin Scaria","userId":"09596160905637401311"},"user_tz":420},"id":"LP8UJSNnILMN","outputId":"3015f9a1-1001-40c5-f31f-f985b7b87788"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["try:\n","    import google.colab\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount = True)\n","    IN_COLAB = True\n","except:\n","    IN_COLAB = False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28574,"status":"ok","timestamp":1670793409962,"user":{"displayName":"Kevin Scaria","userId":"09596160905637401311"},"user_tz":420},"id":"pTZzGWQTQAxt","outputId":"e10b148c-da1e-460a-938c-f56ea19e3bff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 4.1 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 92.3 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 78.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n","\u001b[K     |████████████████████████████████| 451 kB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Collecting xxhash\n","  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 76.8 MB/s \n","\u001b[?25hCollecting multiprocess\n","  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 72.7 MB/s \n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 90.3 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.7.1 multiprocess-0.70.14 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting evaluate\n","  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n","\u001b[K     |████████████████████████████████| 72 kB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from evaluate) (3.1.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2022.11.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.23.0)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.7.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n","Installing collected packages: evaluate\n","Successfully installed evaluate-0.3.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 4.3 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}],"source":["if IN_COLAB:\n","    !pip install transformers\n","    !pip install datasets\n","    !pip install evaluate\n","    !pip install sentencepiece"]},{"cell_type":"code","source":["import os\n","import torch\n","\n","if IN_COLAB:\n","    root_path = '/content/drive/MyDrive/Knowledge/MSIT/Research/InstructABSA'\n","else:\n","    root_path = '/Users/kscaria/Library/CloudStorage/GoogleDrive-scariakevin1@gmail.com/My Drive/Knowledge/MSIT/Research/InstructABSA'\n","    \n","use_mps = True if torch.has_mps else False\n","os.chdir(root_path)"],"metadata":{"id":"lzH6Ya_8-qgd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","import pandas as pd\n","\n","from InstructABSA.utils import T5ATSC\n","from InstructABSA.data_prep import ModelReadyData"],"metadata":{"id":"rOyomlmT-sm6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rest_train_file_path = './Data/semeval14/ABSA_TrainData/Restaurants_Train_v2.csv'\n","laptops_train_file_path = './Data/semeval14/ABSA_TrainData/Laptop_Train_v2.csv'\n","rest_test_file_path = './Data/semeval14/ABSA_Gold_TestData/Restaurants_Test_Gold.csv'\n","laptops_test_file_path = './Data/semeval14/ABSA_Gold_TestData/Laptops_Test_Gold.csv'\n","\n","# Load the data\n","res_tr_df = pd.read_csv(rest_train_file_path)\n","lap_tr_df = pd.read_csv(laptops_train_file_path)\n","res_te_df = pd.read_csv(rest_test_file_path)\n","lap_te_df = pd.read_csv(laptops_test_file_path)"],"metadata":{"id":"QuvpLx1H-0FP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4v8QMMT4B7t"},"outputs":[],"source":["# Extract the aspect term and polarity for each review\n","model_data = ModelReadyData()\n","res_tr_df = model_data.extract_rowwise_aspect_polarity(res_tr_df, on='aspectTerms', by=\"term\", min_val=1)\n","lap_tr_df = model_data.extract_rowwise_aspect_polarity(lap_tr_df, on='aspectTerms', by=\"term\", min_val=1)\n","res_te_df = model_data.extract_rowwise_aspect_polarity(res_te_df, on='aspectTerms', by=\"term\", min_val=1)\n","lap_te_df = model_data.extract_rowwise_aspect_polarity(lap_te_df, on='aspectTerms', by=\"term\", min_val=1)\n","\n","# Get the input text into the required format\n","bos_instruction_lap = \"\"\"Definition: The output will be 'positive' if the aspect identified in the sentence contains a positive sentiment. If the sentiment of the identified aspect in the input is negative the answer will be 'negative'. \n","Otherwise, the output should be 'neutral'. For aspects which are classified as noaspectterm, the sentiment is none. \n","Positive example 1- input: I charge it at night and skip taking the cord with me because of the good battery life. Aspect: battery life. output: positive. \n","Positive example 2- input: I even got my teenage son one, because of the features that it offers, like, iChat, Photobooth, garage band and more!. Aspect: Photobooth. output: positive. \n","Now complete the following example-\n","input: \"\"\"\n","\n","bos_instruction_res = \"\"\"Definition: The output will be 'positive' if the aspect identified in the sentence contains a positive sentiment. If the sentiment of the identified aspect in the input is negative the answer will be 'negative'. \n","Otherwise, the output should be 'neutral'. For aspects which are classified as noaspectterm, the sentiment is none. \n","Positive example 1- input: With the great variety on the menu , I eat here often and never get bored. Aspect: menu. output: positive. \n","Positive example 2- input: Great food, good size menu, great service and an unpretensious setting. Aspect: food. output: positive. \n","Now complete the following example-\n","input: \"\"\"\n","delim_instruction = ' Aspect: '\n","eos_insrtuction = '. Output:'\n","\n","res_tr_df = model_data.create_data_in_atsc_format(res_tr_df, 'raw_text', 'aspect', 'labels', bos_instruction_res, delim_instruction, eos_insrtuction)\n","lap_tr_df = model_data.create_data_in_atsc_format(lap_tr_df, 'raw_text', 'aspect', 'labels', bos_instruction_lap, delim_instruction, eos_insrtuction)\n","res_te_df = model_data.create_data_in_atsc_format(res_te_df, 'raw_text', 'aspect', 'labels', bos_instruction_res, delim_instruction, eos_insrtuction)\n","lap_te_df = model_data.create_data_in_atsc_format(lap_te_df, 'raw_text', 'aspect', 'labels', bos_instruction_lap, delim_instruction, eos_insrtuction)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tZr7BAy6eJOA"},"outputs":[],"source":["# Experimentation\n","experiment_id = 'restaurants'\n","experiment_name = 'restaurants_instruct'\n","model_checkpoint = 'allenai/tk-instruct-base-def-pos'\n","\n","# Create T5 utils object\n","t5_exp = T5ATSC(model_checkpoint, experiment_id, res_tr_df, res_te_df, lap_tr_df, lap_te_df)\n","\n","if IN_COLAB:\n","    model_out_path = os.path.join(root_path, 'T5', 'ATSC')\n","else:\n","    model_out_path = os.getcwd()\n","\n","model_out_path = os.path.join(model_out_path, f\"{model_checkpoint}-{experiment_name}\", \"checkpoints\")\n","print('Model output path: ', model_out_path)\n","\n","\n","# Tokenize Datasets\n","id_dataset, ood_dataset, id_tokenized_dataset, ood_tokenized_dataset = t5_exp.set_data_for_training_semeval(experiment_id)\n","\n","# Training arguments\n","training_args = {\n","    'output_dir':model_out_path,\n","    'evaluation_strategy':\"epoch\",\n","    'learning_rate':5e-5,\n","    'per_device_train_batch_size':16,\n","    'per_device_eval_batch_size':16,\n","    'num_train_epochs':4,\n","    'weight_decay':0.01,\n","    'warmup_ratio':0.1,\n","    'save_strategy':'no',\n","    'load_best_model_at_end':False,\n","    'push_to_hub':False,\n","    'eval_accumulation_steps':1,\n","    'use_mps_device':use_mps\n","}"]},{"cell_type":"code","source":["# Train model\n","model_trainer = t5_exp.train(id_tokenized_dataset, **training_args)"],"metadata":{"id":"kRo4ltS0_G_v"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":243},"executionInfo":{"elapsed":604105,"status":"ok","timestamp":1670795579390,"user":{"displayName":"Kevin Scaria","userId":"09596160905637401311"},"user_tz":420},"id":"U6AlDtjDTi8A","outputId":"e6271fc0-bf0c-4121-e002-495d0836cb72"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 4713\n","  Batch size = 16\n"]},{"output_type":"stream","name":"stdout","text":["Getting model from path:  /content/drive/MyDrive/Knowledge/MSIT/Research/InstructABSA/T5/ATSC/allenai/tk-instruct-base-def-pos-restaurants_instruct/checkpoints\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 1328\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 3915\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 1032\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}}],"source":["# Model inference\n","best_model = 'checkpoints'\n","print('Getting model from path: ', model_out_path)\n","\n","try:\n","    model_trainer\n","except:\n","    model_trainer = None\n","\n","# Get prediction labels - Training set\n","id_tr_pred_labels = t5_exp.get_labels(predictor = model_trainer, tokenized_dataset = id_tokenized_dataset, sample_set = 'train', trained_model_path = model_out_path)\n","\n","# Get prediction labels - Testing set\n","id_te_pred_labels = t5_exp.get_labels(predictor = model_trainer, tokenized_dataset = id_tokenized_dataset, sample_set = 'validation', trained_model_path = model_out_path)\n","\n","# Get prediction labels - OOD Training set\n","ood_tr_pred_labels = t5_exp.get_labels(predictor = model_trainer, tokenized_dataset = ood_tokenized_dataset, sample_set = 'train', trained_model_path = model_out_path)\n","\n","# Get prediction labels - OOD Testing set\n","ood_te_pred_labels = t5_exp.get_labels(predictor = model_trainer, tokenized_dataset = ood_tokenized_dataset, sample_set = 'validation', trained_model_path = model_out_path)"]},{"cell_type":"code","source":["# Add new column in the respective dataframes\n","id_tr_df = pd.DataFrame(id_dataset['train'])\n","id_te_df = pd.DataFrame(id_dataset['validation'])\n","ood_tr_df = pd.DataFrame(ood_dataset['train'])\n","ood_te_df = pd.DataFrame(ood_dataset['validation'])\n","\n","id_tr_df['pred_labels'] = id_tr_pred_labels\n","id_te_df['pred_labels'] = id_te_pred_labels\n","ood_tr_df['pred_labels'] = ood_tr_pred_labels\n","ood_te_df['pred_labels'] = ood_te_pred_labels\n","\n","# Metrics\n","print('In domain train accuracy: ', id_tr_df[['labels', 'pred_labels']].apply(lambda x: x[0] == x[1], axis=1).sum()*100/len(id_tr_df))\n","print('In domain test accuracy: ', id_te_df[['labels', 'pred_labels']].apply(lambda x: x[0] == x[1], axis=1).sum()*100/len(id_te_df))\n","\n","ood_df = pd.concat([ood_tr_df, ood_te_df])\n","print('Out of domain accuracy: ', ood_df[['labels', 'pred_labels']].apply(lambda x: x[0] == x[1], axis=1).sum()*100/len(ood_df))\n","print('Out of domain train accuracy: ', ood_tr_df[['labels', 'pred_labels']].apply(lambda x: x[0] == x[1], axis=1).sum()*100/len(ood_tr_df))\n","print('Out of domain test accuracy: ', ood_te_df[['labels', 'pred_labels']].apply(lambda x: x[0] == x[1], axis=1).sum()*100/len(ood_te_df))\n","\n","#Dump outputs\n","dump_path = '/'.join(model_out_path.split('/')[:-1])\n","id_tr_filename = t5_exp.get_csv_filename(experiment_id)[0]\n","id_tr_df.to_csv(os.path.join(dump_path, id_tr_filename), index = False)\n","\n","id_te_filename = t5_exp.get_csv_filename(experiment_id)[1]\n","id_te_df.to_csv(os.path.join(dump_path, id_te_filename), index = False)\n","\n","ood_tr_filename = t5_exp.get_csv_filename(experiment_id)[2]\n","ood_tr_df.to_csv(os.path.join(dump_path, ood_tr_filename), index = False)\n","\n","ood_te_filename = t5_exp.get_csv_filename(experiment_id)[3]\n","ood_te_df.to_csv(os.path.join(dump_path, ood_te_filename), index = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FwWwCA5J_MVP","executionInfo":{"status":"ok","timestamp":1670795766516,"user_tz":420,"elapsed":804,"user":{"displayName":"Kevin Scaria","userId":"09596160905637401311"}},"outputId":"66176a07-e476-4c8d-e5d4-238c65f8e85b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["In domain train accuracy:  90.60046679397412\n","In domain test accuracy:  87.42469879518072\n","Out of domain accuracy:  86.3957954315747\n","Out of domain train accuracy:  86.18135376756067\n","Out of domain test accuracy:  87.20930232558139\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}